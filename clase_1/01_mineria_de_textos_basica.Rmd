---
title: "Minería de textos básica"
author: "Roberto Muñoz"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  github_document:
    toc: true
    toc_depth: 2
    #number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Ajustamos el locale del sistema de acuerdo al OS del computador
En caso de usar un Mac ejecute la siguiente linea
```{r}
Sys.setlocale("LC_ALL", 'en_US.UTF-8')
```

En caso de usar Windows ejecute la siguiente linea
```{r}
Sys.setlocale("LC_ALL", 'Spanish_Chile.1252')
```

# Instalamos y cargamos las librerías que usaremos
```{r}
install.packages(c('tm', 'SnowballC', 'wordcloud', 'topicmodels'))
```

```{r}
library(tm)
library(SnowballC)
library(wordcloud)
```

# Lectura de datos
Usaremos una base de datos que contiene información acerca 
Next we load the move review dataset

```{r}
reviews = read.csv("data/movie-pang02.csv", stringsAsFactors = F)
View(reviews)
```

El dataset review dataset contiene dos campos: valoracion (Pos y Neg) y contenido. Transformamos este dataset en un corpus.

```{r}
review_corpus = Corpus(VectorSource(reviews$contenido))
```

Normalizamos el texto de los reviews aplicando una serie de pasos en el pre procesamiento,
1. Conversión de contenido a minúsuculas
2. Eliminar números
3. Eliminar puntuación y palabras sin significado como artículos, pronombres, preposiciones (stopwords).
4. Eliminar espacios en blanco

```{r}
review_corpus = tm_map(review_corpus, content_transformer(tolower))
review_corpus = tm_map(review_corpus, removeNumbers)
review_corpus = tm_map(review_corpus, removePunctuation)
review_corpus = tm_map(review_corpus, removeWords, c("the", "and", stopwords("english")))
review_corpus =  tm_map(review_corpus, stripWhitespace)
```

```{r}
inspect(review_corpus[1])
```

Para analizar datos en forma de texto, usamos una representación del tipo Document-Term Matrix (DTM): Documentos como filas, palabras como columnas, frecuencia de las palabras en el documento como valores. Debido al número de palabras únicas en el corpus esta matriz puede ser muy grande.

```{r}
review_dtm <- DocumentTermMatrix(review_corpus)
review_dtm
```

Inspeccionamos una pequeña sección de esta matriz

```{r}
inspect(review_dtm[500:505, 500:505])
```

Para reducir la dimnesionalidad de la matriz DTM, podemos eliminar las palabras menos frecuentes. Para ellos usamos la función removeSparseTerms() y el valor 99 para la dispersión.

```{r}
review_dtm = removeSparseTerms(review_dtm, 0.99)
review_dtm
```

Veamos el primer review

```{r}
inspect(review_dtm[1,1:20])
```

Construyamos una nuebe palabras usando la función findFreqTerms() y usemos solamente las palabras que tienen una frecuencia absoluta de al menos 1000. 

```{r}
findFreqTerms(review_dtm, 1000)
```

Usemos la función wordcloud() para mostrarlas gráficamente

```{r}
freq = data.frame(sort(colSums(as.matrix(review_dtm)), decreasing=TRUE))
wordcloud(rownames(freq), freq[,1], max.words=50, colors=brewer.pal(1, "Dark2"))
```

Un podría argumentar que en la nube de palabras, los términos one, film y movie no son del todo relavantes, pues ya sabemos que el dataset es acerca de películas.

En este tipo de situaciones es conveniente usar la métrica tf-idf (term frequency-inverse document frequency) en vez de la frecuencia de los términos como valor en la matriz DTM. La métrica tf-idf mide la importancia relativa de las palabras en un documento.

```{r}
review_dtm_tfidf <- DocumentTermMatrix(review_corpus, control = list(weighting = weightTfIdf))
review_dtm_tfidf = removeSparseTerms(review_dtm_tfidf, 0.95)
review_dtm_tfidf
```

Veamos el primer review

```{r}
inspect(review_dtm[1,1:20])
```

Generemos una nueva nube de palabras

```{r}
freq = data.frame(sort(colSums(as.matrix(review_dtm_tfidf)), decreasing=TRUE))
wordcloud(rownames(freq), freq[,1], max.words=100, scale = c(4, 0.5), colors=brewer.pal(1, "Dark2"))
```

# Construcción de modelo predictivo

Para predecir la polaridad (sentimiento) de una crítica de película, podemos usar un a lista precompilada de palabras con significado positivo y negativo.

```{r}
neg_words = read.table("data/negative-words.txt", header = F, stringsAsFactors = F)[, 1]
pos_words = read.table("data/positive-words.txt", header = F, stringsAsFactors = F)[, 1]
```

Como un simple indicar, creamos dos campos (neg y pos) que contendrán el número de palabras positivas y negativas que aparecen en cada crítica

```{r}
reviews$neg = sapply(review_corpus, tm_term_score, neg_words)
reviews$pos = sapply(review_corpus, tm_term_score, pos_words)
```


