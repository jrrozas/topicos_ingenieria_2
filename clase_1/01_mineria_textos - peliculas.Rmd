---
title: "Minería de textos básica"
author: "Roberto Muñoz"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  github_document:
    toc: true
    toc_depth: 2
    #number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Ajustamos el locale del sistema de acuerdo al OS del computador

```{r}
#En caso de usa Mac OS X
Sys.setlocale("LC_ALL", 'en_US.UTF-8')
#En caso de usa Windows
#Sys.setlocale("LC_ALL", 'Spanish_Chile.1252')
```

# Instalamos y cargamos las librerías que usaremos
```{r}
install_load_library <- function(x){
  for( i in x ){
    if( ! require( i , character.only = TRUE ) ){
      install.packages( i , dependencies = TRUE )
      require( i , character.only = TRUE )
    }
  }
}

#  Then try/install packages...
install_load_library( c('tm', 'SnowballC', 'wordcloud', 'topicmodels') )
```

# Lectura de datos
Usaremos una base de datos que contiene 2 mil críticas de películas de cine. Las críticas están escritas en inglés, fueron  y fueron publicadas por 

```{r}
reviews = read.csv("https://github.com/rpmunoz/topicos_ingenieria_2/raw/master/clase_1/data/movie_reviews - pang_lee_2004.csv", stringsAsFactors = F)
#View(reviews)
```

El dataset review dataset contiene dos campos: valoracion (Pos y Neg) y contenido. Transformamos este dataset en un corpus.

```{r}
review_corpus = Corpus(VectorSource(reviews$contenido))
```

Normalizamos el texto de los reviews aplicando una serie de pasos en el pre procesamiento,
1. Conversión de contenido a minúsuculas
2. Eliminar números
3. Eliminar puntuación y palabras sin significado como artículos, pronombres, preposiciones (stopwords).
4. Eliminar espacios en blanco

```{r}
review_corpus = tm_map(review_corpus, content_transformer(tolower))
review_corpus = tm_map(review_corpus, removeNumbers)
review_corpus = tm_map(review_corpus, removePunctuation)
review_corpus = tm_map(review_corpus, removeWords, c("the", "and", "re", "s", stopwords("english")))
review_corpus =  tm_map(review_corpus, stripWhitespace)
```

```{r}
inspect(review_corpus[3])
```

Para analizar datos en forma de texto, usamos una representación del tipo Document-Term Matrix (DTM): Documentos como filas, palabras como columnas, frecuencia de las palabras en el documento como valores. Debido al número de palabras únicas en el corpus esta matriz puede ser muy grande.

```{r}
review_dtm <- DocumentTermMatrix(review_corpus)
review_dtm
```

Inspeccionamos una pequeña sección de esta matriz

```{r}
inspect(review_dtm[500:505, 100:105])
```

Para reducir la dimnesionalidad de la matriz DTM, podemos eliminar las palabras menos frecuentes. Para ellos usamos la función removeSparseTerms() y el valor 99 para la dispersión.

```{r}
review_dtm = removeSparseTerms(review_dtm, 0.99)
review_dtm
```

Veamos el primer review

```{r}
inspect(review_dtm[1,1:20])
```

Construyamos una nuebe palabras usando la función findFreqTerms() y usemos solamente las palabras que tienen una frecuencia absoluta de al menos 1000. 

```{r}
findFreqTerms(review_dtm, 1000)
```

Usemos la función wordcloud() para mostrarlas gráficamente

```{r}
freq = data.frame(sort(colSums(as.matrix(review_dtm)), decreasing=TRUE))
wordcloud(rownames(freq), freq[,1], max.words=100, colors=brewer.pal(8, "Dark2"))
```

Un podría argumentar que en la nube de palabras, los términos one, film y movie no son del todo relavantes, pues ya sabemos que el dataset es acerca de películas.

En este tipo de situaciones es conveniente usar la métrica tf-idf (term frequency-inverse document frequency) en vez de la frecuencia de los términos como valor en la matriz DTM. La métrica tf-idf mide la importancia relativa de las palabras en un documento.

```{r}
review_dtm_tfidf <- DocumentTermMatrix(review_corpus, control = list(weighting = weightTfIdf))
review_dtm_tfidf = removeSparseTerms(review_dtm_tfidf, 0.95)
review_dtm_tfidf
```

Veamos el primer review

```{r}
inspect(review_dtm[1,1:20])
```

Generemos una nueva nube de palabras

```{r}
freq = data.frame(sort(colSums(as.matrix(review_dtm_tfidf)), decreasing=TRUE))
wordcloud(rownames(freq), freq[,1], max.words=30, scale = c(3, 0.3), colors=brewer.pal(8, "Dark2"))
```




